{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spotify Popularity - Neural Network (TensorFlow + KerasTuner)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys  # ‚úì sys'i en ba≈üta import et\n",
    "import os\n",
    "sys.path.append('d:/spotifyTrendAnalysis')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # TensorFlow uyarƒ±larƒ±nƒ± gizle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#!pip install keras_tuner\n",
    "import keras_tuner as kt\n",
    "RANDOM_STATE = 24\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "import importlib\n",
    "if 'EngineerFeature' in sys.modules:\n",
    "    importlib.reload(sys.modules['EngineerFeature'])\n",
    "from EngineerFeature import FeatureEngineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a5f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../final_data.csv\")\n",
    "#df = df[:5000]\n",
    "# y = df[\"popularity\"].values.reshape(-1, 1)\n",
    "\n",
    "# qt = QuantileTransformer(output_distribution=\"normal\", random_state=42)\n",
    "# df[\"popularity\"] = qt.fit_transform(y).ravel()\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.histplot(df['popularity'], bins=30, kde=True)\n",
    "# plt.title(\"Track Popularity Distribution\")\n",
    "# plt.xlabel(\"Popularity\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a99b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"popularity\", axis=1)\n",
    "y = df[\"popularity\"]\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886523dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Veri b√∂l√ºnmesi: Train (60%) / Val (20%) / Test (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Feature Engineering uygula\n",
    "fe = FeatureEngineer()\n",
    "X_temp = fe.fit_transform(X_temp, y_temp)\n",
    "X_test = fe.transform(X_test)\n",
    "\n",
    "# Train ve Validation'ƒ± ayƒ±r\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.25,  # 0.25 * 0.8 = 0.2 (20% val)\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train+Val:\", X_temp.shape, y_temp.shape, \"‚Üí %80 of data\")\n",
    "print(\"Train:    \", X_train.shape, y_train.shape, \"‚Üí %60 of data\")\n",
    "print(\"Val:      \", X_val.shape,   y_val.shape, \"‚Üí %20 of data\")\n",
    "print(\"Test:     \", X_test.shape,  y_test.shape, \"‚Üí %20 of data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6661c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def build_model(hp: kt.HyperParameters):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(42,)))\n",
    "\n",
    "    # ka√ß tane hidden layer\n",
    "    n_layers = hp.Int(\"n_layers\", min_value=2, max_value=4)\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        units = hp.Int(f\"units_{i}\", min_value=32, max_value=64, step=32)\n",
    "        model.add(layers.Dense(units, activation=\"relu\"))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        dropout_rate = hp.Float(f\"dropout_{i}\", min_value=0.0, max_value=0.15, step=0.05)\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    # output layer (regression ‚Üí 1 n√∂ron)\n",
    "    model.add(layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "    # learning rate\n",
    "    lr = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-3, sampling=\"log\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"mae\", #keras.losses.Huber(),\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979808a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Eski tuner loglarƒ±nƒ± temizle (yeni aramaya ba≈ülamak i√ßin)\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists(\"nn_tuner_logs\"):\n",
    "    shutil.rmtree(\"nn_tuner_logs\")\n",
    "    print(\"üóëÔ∏è Eski tuner loglarƒ± silindi, yeni arama ba≈ülƒ±yor...\")\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=10,           # 15 farklƒ± kombinasyon deneyecek\n",
    "    directory=\"nn_tuner_logs\",\n",
    "    project_name=\"spotify_popularity_nn\",\n",
    "    overwrite=True           # Eski sonu√ßlarƒ±n √ºzerine yaz\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a25a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,           # istersen bunu da hp'ye a√ßabiliriz\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best hyperparameters:\", best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a892bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = best_model.fit(\n",
    "    X_temp, y_temp,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ddae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
