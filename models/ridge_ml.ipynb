{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97995140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) alpha â€” Regularization gÃ¼cÃ¼ (en Ã¶nemli parametre!)\\n\\nCeza katsayÄ±sÄ±dÄ±r (L2 penalty).\\n\\nAlpha â†‘ â†’ Daha gÃ¼Ã§lÃ¼ regularizasyon â†’ KatsayÄ±lar kÃ¼Ã§Ã¼lÃ¼r â†’ Overfitting azalÄ±r.\\n\\nAlpha â†“ â†’ Regularizasyon azalÄ±r â†’ Model daha esnek â†’ Overfitting riski artar.\\n\\nâž¡ En kritik hiperparametre.\\nðŸŸ© 2) solver â€” Ã‡Ã¶zÃ¼m algoritmasÄ±\\n\\nModeli hangi optimizasyon yÃ¶ntemiyle Ã§Ã¶zeceÄŸini belirler.\\n\\nKÄ±saca:\\n\\nâ€˜autoâ€™ â†’ sklearn kendisi karar verir\\n\\nâ€˜sagâ€™ / â€˜sagaâ€™ â†’ bÃ¼yÃ¼k ve yÃ¼ksek boyutlu veri iÃ§in hÄ±zlÄ±\\n\\nâ€˜lbfgsâ€™ â†’ kÃ¼Ã§Ã¼kâ€“orta veri iÃ§in Ã§ok stabil\\n\\nâ€˜lsqrâ€™ / â€˜sparse_cgâ€™ â†’ sparse matrisler iÃ§in iyi\\n\\nâ€˜svdâ€™ / â€˜choleskyâ€™ â†’ kapalÄ± form Ã§Ã¶zÃ¼mler (kÃ¼Ã§Ã¼k veri iÃ§in)\\n\\nâž¡ Verinin boyutuna gÃ¶re hÄ±z/stabilite fark eder.\\nðŸŸ¨ 3) max_iter â€” Maksimum iterasyon sayÄ±sÄ±\\n\\nSolver iteratif Ã§alÄ±ÅŸÄ±yorsa:\\n\\nmax_iter Ã§Ã¶zÃ¼me ulaÅŸmak iÃ§in izin verilen en fazla adÄ±m.\\n\\nYetmezse ConvergenceWarning verir.\\n\\nâž¡ Genelde 1000â€“5000 yeterli.\\n\\nðŸŸ§ 4) tol â€” Durdurma eÅŸiÄŸi (convergence toleransÄ±)\\n\\nModel optimizasyonu ne zaman durduracak?\\n\\nKÃ¼Ã§Ã¼k tol â†’ daha hassas Ã§Ã¶zÃ¼m â†’ daha uzun sÃ¼re\\n\\nBÃ¼yÃ¼k tol â†’ daha hÄ±zlÄ± ama daha kaba Ã§Ã¶zÃ¼m\\n\\nâž¡ VarsayÄ±lan (1e-4) Ã§oÄŸu zaman yeterli.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"1) alpha â€” Regularization gÃ¼cÃ¼ (en Ã¶nemli parametre!)\n",
    "\n",
    "Ceza katsayÄ±sÄ±dÄ±r (L2 penalty).\n",
    "\n",
    "Alpha â†‘ â†’ Daha gÃ¼Ã§lÃ¼ regularizasyon â†’ KatsayÄ±lar kÃ¼Ã§Ã¼lÃ¼r â†’ Overfitting azalÄ±r.\n",
    "\n",
    "Alpha â†“ â†’ Regularizasyon azalÄ±r â†’ Model daha esnek â†’ Overfitting riski artar.\n",
    "\n",
    "âž¡ En kritik hiperparametre.\n",
    "ðŸŸ© 2) solver â€” Ã‡Ã¶zÃ¼m algoritmasÄ±\n",
    "\n",
    "Modeli hangi optimizasyon yÃ¶ntemiyle Ã§Ã¶zeceÄŸini belirler.\n",
    "\n",
    "KÄ±saca:\n",
    "\n",
    "â€˜autoâ€™ â†’ sklearn kendisi karar verir\n",
    "\n",
    "â€˜sagâ€™ / â€˜sagaâ€™ â†’ bÃ¼yÃ¼k ve yÃ¼ksek boyutlu veri iÃ§in hÄ±zlÄ±\n",
    "\n",
    "â€˜lbfgsâ€™ â†’ kÃ¼Ã§Ã¼kâ€“orta veri iÃ§in Ã§ok stabil\n",
    "\n",
    "â€˜lsqrâ€™ / â€˜sparse_cgâ€™ â†’ sparse matrisler iÃ§in iyi\n",
    "\n",
    "â€˜svdâ€™ / â€˜choleskyâ€™ â†’ kapalÄ± form Ã§Ã¶zÃ¼mler (kÃ¼Ã§Ã¼k veri iÃ§in)\n",
    "\n",
    "âž¡ Verinin boyutuna gÃ¶re hÄ±z/stabilite fark eder.\n",
    "ðŸŸ¨ 3) max_iter â€” Maksimum iterasyon sayÄ±sÄ±\n",
    "\n",
    "Solver iteratif Ã§alÄ±ÅŸÄ±yorsa:\n",
    "\n",
    "max_iter Ã§Ã¶zÃ¼me ulaÅŸmak iÃ§in izin verilen en fazla adÄ±m.\n",
    "\n",
    "Yetmezse ConvergenceWarning verir.\n",
    "\n",
    "âž¡ Genelde 1000â€“5000 yeterli.\n",
    "\n",
    "ðŸŸ§ 4) tol â€” Durdurma eÅŸiÄŸi (convergence toleransÄ±)\n",
    "\n",
    "Model optimizasyonu ne zaman durduracak?\n",
    "\n",
    "KÃ¼Ã§Ã¼k tol â†’ daha hassas Ã§Ã¶zÃ¼m â†’ daha uzun sÃ¼re\n",
    "\n",
    "BÃ¼yÃ¼k tol â†’ daha hÄ±zlÄ± ama daha kaba Ã§Ã¶zÃ¼m\n",
    "\n",
    "âž¡ VarsayÄ±lan (1e-4) Ã§oÄŸu zaman yeterli.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbfc5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('d:/spotifyTrendAnalysis')\n",
    "import importlib\n",
    "if 'EngineerFeature' in sys.modules:\n",
    "    importlib.reload(sys.modules['EngineerFeature'])\n",
    "from EngineerFeature import FeatureEngineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081f78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_data.csv')\n",
    "#data = data[:1000]\n",
    "X = data.drop('popularity', axis=1)\n",
    "y = data['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de39ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'alpha': [0.1, 1.0, 10.0, 100.0, 200.0, 500.0],\n",
    "    'solver': ['sag', 'auto', 'lsqr', 'sparse_cg'],\n",
    "    'tol': [1e-3, 1e-2, 1e-1],\n",
    "    'max_iter': [1000, 2000, 5000, 7500, 10000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67075c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_ridge(X, y, grid):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    keys = grid.keys()\n",
    "    values = grid.values()\n",
    "\n",
    "    best_r2 = -float('inf')\n",
    "    for combo in itertools.product(*values):\n",
    "        params = dict(zip(keys, combo))\n",
    "\n",
    "        model = Ridge(**params)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        #print(f\"Params: {params}, R2: {r2}\")\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_params = params\n",
    "\n",
    "    return best_params, best_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4594bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The best parameters are:  {'alpha': 0.1, 'solver': 'sag', 'tol': 0.01, 'max_iter': 7500}\n",
      "Best R2 score:  0.5870717825998937\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "fe = FeatureEngineer()\n",
    "X_train = fe.fit_transform(X_train1, y_train1)\n",
    "X_test = fe.transform(X_test1)\n",
    "best_params, best_r2 = grid_search_ridge(X_train1, y_train1, grid)\n",
    "print(\"\\n\\nThe best parameters are: \", best_params)\n",
    "print(\"Best R2 score: \", best_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2af8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score with best parameters on test set:  0.5968439178629816\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(**best_params)\n",
    "scaler = StandardScaler()\n",
    "X_train1_scaled = scaler.fit_transform(X_train1)\n",
    "X_test1_scaled = scaler.transform(X_test1)\n",
    "model.fit(X_train1_scaled, y_train1)\n",
    "y_pred = model.predict(X_test1_scaled)\n",
    "r2 = r2_score(y_test1, y_pred)\n",
    "print(\"R2 score with best parameters on test set: \", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
